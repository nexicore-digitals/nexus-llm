# ðŸ§  NexusLLM Model Registry

This registry defines the cognitive landscape of NexusLLMâ€”each model is a modular neuron in Nexiâ€™s cortex. Models are grouped by family, annotated with metadata, and ready for plugin-aware orchestration.

---

## ðŸ“¦ Model Schema

Each model entry follows this structure:

```ts
{
  name: "phi3",
  family: "Phi",
  developer: "Microsoft",
  params: ["3.8B", "7B", "14B", "42B (MoE)"],
  contextWindow: ["4k", "8k", "128k"],
  useCases: ["text", "code", "math", "multilingual", "on-device"],
  license: "Microsoft Research License",
  pluginCompatibility: ["RegexPlugin", "MemoryPlugin", "ToolRouterPlugin"],
  notes: "Fast, compact, ideal for validation and reasoning tasks"
}
```

---

## ðŸ§  Registered Models

### ðŸŸ¦ Phi-3 / Phi-4

- **Family**: Phi
- **Developer**: Microsoft
- **Params**: 3.8B, 7B, 14B, 42B (MoE)
- **Context Window**: 4k, 8k, 128k, 16k (Phi-4)
- **Use-Cases**: General text, multilingual, code understanding, math reasoning, on-device inference
- **License**: Microsoft Research License
- **Plugin Compatibility**: âœ… Regex, âœ… Memory, âœ… ToolRouter
- **Notes**: Compact, fast, ideal for validation and schema-aware flows

---

### ðŸŸ¨ Gemini 2.5 Flash

- **Family**: Gemini
- **Developer**: Google
- **Params**: 2B, 9B, 27B
- **Context Window**: 8k
- **Use-Cases**: Summarization, QA, general text, code generation
- **License**: Gemma License
- **Plugin Compatibility**: âœ… DocPlugin, âœ… ExplainerPlugin
- **Notes**: Fastest responder, ideal as class prefect for MCP orchestration

---

### ðŸŸ§ Mixtral / Mistral

- **Family**: Mistral
- **Developer**: Mistral AI
- **Params**: 3Bâ€“124B
- **Context Window**: 32kâ€“128k
- **Use-Cases**: High-complexity tasks, multilingual, code, image, function calling
- **License**: Apache 2.0 / Commercial
- **Plugin Compatibility**: âœ… Regex, âœ… ToolRouter, âœ… Memory
- **Notes**: Ideal for deep reasoning, fallback, and ensemble validation

---

### ðŸŸ¥ Falcon 3

- **Family**: Falcon
- **Developer**: TII
- **Params**: 1B, 3B, 7B, 10B
- **Context Window**: 8kâ€“32k
- **Use-Cases**: General text, code, math, scientific knowledge
- **License**: TII Falcon License
- **Plugin Compatibility**: âœ… DocPlugin, âœ… RegexPlugin
- **Notes**: Strong in scientific and multilingual flows

---

### ðŸŸ© Gemma 2

- **Family**: Gemma
- **Developer**: Google
- **Params**: 2B, 9B, 27B
- **Context Window**: 8k
- **Use-Cases**: Text generation, QA, summarization, code
- **License**: Gemma License
- **Plugin Compatibility**: âœ… DocPlugin
- **Notes**: Lightweight, schema-friendly, ideal for onboarding flows

---

### ðŸŸª StarCoder2

- **Family**: BigCode
- **Developer**: BigCode
- **Params**: 3B, 7B, 15B
- **Context Window**: 16k
- **Use-Cases**: Code completion, multi-language programming
- **License**: Apache 2.0
- **Plugin Compatibility**: âœ… RegexPlugin, âœ… ExplainerPlugin
- **Notes**: Ideal for contributor coding flows and reviewable suggestions

---

### ðŸŸ« Yi

- **Family**: Yi
- **Developer**: 01.AI
- **Params**: 6B, 9B, 34B
- **Context Window**: 4k, 8k, 200k
- **Use-Cases**: Bilingual generation, code, math, reasoning
- **License**: Apache 2.0
- **Plugin Compatibility**: âœ… RegexPlugin, âœ… ToolRouterPlugin
- **Notes**: High-context, multilingual, ideal for edge cognition

---

### ðŸŸ¦ Qwen2.5

- **Family**: Qwen
- **Developer**: Alibaba
- **Params**: 0.5Bâ€“72B
- **Context Window**: 128k
- **Use-Cases**: Text, multilingual, code, math, structured data
- **License**: Apache 2.0 / Qwen License
- **Plugin Compatibility**: âœ… ToolRouterPlugin, âœ… MemoryPlugin
- **Notes**: Ideal for structured data flows and schema hydration

---

### ðŸŸ§ DeepSeek V2/V3

- **Family**: DeepSeek
- **Developer**: DeepSeek AI
- **Params**: 16B, 236B, 671B (V3)
- **Context Window**: 32kâ€“128k
- **Use-Cases**: Text, multilingual, code, advanced reasoning
- **License**: DeepSeek License
- **Plugin Compatibility**: âœ… RegexPlugin, âœ… ToolRouterPlugin
- **Notes**: High-capacity, ideal for ensemble fallback and schema-heavy flows

---

### ðŸŸ¨ StableLM 2

- **Family**: StableLM
- **Developer**: Stability AI
- **Params**: 1.6B, 3B, 12B
- **Context Window**: Up to 16k
- **Use-Cases**: Multilingual text, code, fine-tuning
- **License**: Stability AI Community / Enterprise
- **Plugin Compatibility**: âœ… RegexPlugin, âœ… DocPlugin
- **Notes**: Lightweight, ideal for contributor onboarding and schema validation

---

### ðŸŸ« Command R

- **Family**: Command R
- **Developer**: Cohere
- **Params**: 7B, 35B, 104B
- **Context Window**: 128k
- **Use-Cases**: Conversational AI, RAG, tool use, long-form generation
- **License**: CC-BY-NC 4.0
- **Plugin Compatibility**: âœ… ToolRouterPlugin, âœ… MemoryPlugin
- **Notes**: Ideal for tool-aware flows and long-form contributor feedback

---

## ðŸ§  Model Selection Logic (MCP)

Nexi uses this registry to assign models based on:

- **Model**: Capability and context window
- **Context**: Schema complexity, contributor state
- **Policy**: License constraints, plugin compatibility
- **Fallback**: Availability, cost, performance

---

## ðŸ“Ž Future Extensions

- Add `costEstimate` and `latencyProfile` fields
- Add `schemaAffinity` tags for NexusDSM compatibility
- Add `toolCallingSupport` flag for plugin routing
- Add `streamingSupport` flag for emotional architecture

---

This registry is alive. Every model is a neuron. Every plugin is a tool. Every contributor is a signal.  
Nexi reads this file like a cognitive mapâ€”and routes accordingly.
